{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e64f5f7",
   "metadata": {},
   "source": [
    "# UNDERSTANDING NEED DROPOUT LAYER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df81b681",
   "metadata": {},
   "source": [
    "**Importing Liberaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9b50063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68f3bfdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "\n",
       "[4 rows x 61 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"S:/Github/DATASET/sonar_dataset.csv\" , header=None)\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8d650c",
   "metadata": {},
   "source": [
    "**Creating Train and Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ba124a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60\n",
       "1    111\n",
       "0     97\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.drop(columns = 60)\n",
    "y = data[60]\n",
    "\n",
    "y = y.replace({\"R\" :0 , \"M\" : 1})\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c52122bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((166, 60), (42, 60), (166,), (42,))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=5)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448d1b90",
   "metadata": {},
   "source": [
    "**Creating Model Without dropout layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de4b7fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\13zer\\anaconda3\\envs\\dl\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.5821 - loss: 0.6858 - val_accuracy: 0.6176 - val_loss: 0.6826\n",
      "Epoch 2/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7614 - loss: 0.6718 - val_accuracy: 0.6176 - val_loss: 0.6774\n",
      "Epoch 3/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6935 - loss: 0.6640 - val_accuracy: 0.6471 - val_loss: 0.6615\n",
      "Epoch 4/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6867 - loss: 0.6505 - val_accuracy: 0.5882 - val_loss: 0.6659\n",
      "Epoch 5/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7741 - loss: 0.6021 - val_accuracy: 0.6176 - val_loss: 0.6315\n",
      "Epoch 6/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7246 - loss: 0.5857 - val_accuracy: 0.6176 - val_loss: 0.6230\n",
      "Epoch 7/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7606 - loss: 0.5648 - val_accuracy: 0.6471 - val_loss: 0.5951\n",
      "Epoch 8/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8008 - loss: 0.5172 - val_accuracy: 0.7353 - val_loss: 0.5677\n",
      "Epoch 9/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7961 - loss: 0.4958 - val_accuracy: 0.7059 - val_loss: 0.5605\n",
      "Epoch 10/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8065 - loss: 0.4151 - val_accuracy: 0.4412 - val_loss: 0.7400\n",
      "Epoch 11/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7721 - loss: 0.4380 - val_accuracy: 0.7353 - val_loss: 0.5378\n",
      "Epoch 12/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8304 - loss: 0.4156 - val_accuracy: 0.6765 - val_loss: 0.5918\n",
      "Epoch 13/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8439 - loss: 0.3820 - val_accuracy: 0.7059 - val_loss: 0.6042\n",
      "Epoch 14/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8305 - loss: 0.4025 - val_accuracy: 0.6765 - val_loss: 0.5845\n",
      "Epoch 15/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8369 - loss: 0.4012 - val_accuracy: 0.6765 - val_loss: 0.5896\n",
      "Epoch 16/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9008 - loss: 0.2918 - val_accuracy: 0.6765 - val_loss: 0.6076\n",
      "Epoch 17/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8200 - loss: 0.3747 - val_accuracy: 0.5588 - val_loss: 0.7759\n",
      "Epoch 18/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8576 - loss: 0.3571 - val_accuracy: 0.7059 - val_loss: 0.6734\n",
      "Epoch 19/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8863 - loss: 0.2778 - val_accuracy: 0.7647 - val_loss: 0.5713\n",
      "Epoch 20/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8593 - loss: 0.3090 - val_accuracy: 0.6471 - val_loss: 0.7108\n",
      "Epoch 21/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8884 - loss: 0.2783 - val_accuracy: 0.6765 - val_loss: 0.6181\n",
      "Epoch 22/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8997 - loss: 0.2756 - val_accuracy: 0.7059 - val_loss: 0.6720\n",
      "Epoch 23/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9207 - loss: 0.2623 - val_accuracy: 0.6765 - val_loss: 0.6555\n",
      "Epoch 24/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9017 - loss: 0.2507 - val_accuracy: 0.7647 - val_loss: 0.5768\n",
      "Epoch 25/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8811 - loss: 0.2939 - val_accuracy: 0.7647 - val_loss: 0.6036\n",
      "Epoch 26/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9239 - loss: 0.2511 - val_accuracy: 0.7059 - val_loss: 0.6907\n",
      "Epoch 27/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9277 - loss: 0.2144 - val_accuracy: 0.7353 - val_loss: 0.6165\n",
      "Epoch 28/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9136 - loss: 0.2295 - val_accuracy: 0.6765 - val_loss: 0.6445\n",
      "Epoch 29/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9297 - loss: 0.1747 - val_accuracy: 0.7059 - val_loss: 0.7400\n",
      "Epoch 30/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9224 - loss: 0.1872 - val_accuracy: 0.6765 - val_loss: 0.6550\n",
      "Epoch 31/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8693 - loss: 0.2118 - val_accuracy: 0.7353 - val_loss: 0.6205\n",
      "Epoch 32/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9282 - loss: 0.1642 - val_accuracy: 0.7353 - val_loss: 0.6419\n",
      "Epoch 33/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9483 - loss: 0.1492 - val_accuracy: 0.6765 - val_loss: 0.7288\n",
      "Epoch 34/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9477 - loss: 0.1696 - val_accuracy: 0.7059 - val_loss: 0.6624\n",
      "Epoch 35/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9507 - loss: 0.1353 - val_accuracy: 0.6765 - val_loss: 0.7079\n",
      "Epoch 36/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9466 - loss: 0.1251 - val_accuracy: 0.7353 - val_loss: 0.6851\n",
      "Epoch 37/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9905 - loss: 0.1004 - val_accuracy: 0.7059 - val_loss: 0.7457\n",
      "Epoch 38/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9893 - loss: 0.1169 - val_accuracy: 0.7647 - val_loss: 0.6964\n",
      "Epoch 39/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9861 - loss: 0.0983 - val_accuracy: 0.7941 - val_loss: 0.7168\n",
      "Epoch 40/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9693 - loss: 0.0970 - val_accuracy: 0.6765 - val_loss: 0.7517\n",
      "Epoch 41/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9656 - loss: 0.0926 - val_accuracy: 0.6765 - val_loss: 0.7970\n",
      "Epoch 42/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9897 - loss: 0.0851 - val_accuracy: 0.7353 - val_loss: 0.7678\n",
      "Epoch 43/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9893 - loss: 0.0843 - val_accuracy: 0.7353 - val_loss: 0.7576\n",
      "Epoch 44/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9972 - loss: 0.0763 - val_accuracy: 0.7353 - val_loss: 0.7471\n",
      "Epoch 45/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0627 - val_accuracy: 0.7353 - val_loss: 0.7627\n",
      "Epoch 46/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9987 - loss: 0.0572 - val_accuracy: 0.7353 - val_loss: 0.7866\n",
      "Epoch 47/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9972 - loss: 0.0479 - val_accuracy: 0.7353 - val_loss: 0.7980\n",
      "Epoch 48/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0404 - val_accuracy: 0.7353 - val_loss: 0.8084\n",
      "Epoch 49/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0427 - val_accuracy: 0.7647 - val_loss: 0.8169\n",
      "Epoch 50/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0430 - val_accuracy: 0.7353 - val_loss: 0.8153\n",
      "Epoch 51/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0359 - val_accuracy: 0.7353 - val_loss: 0.8428\n",
      "Epoch 52/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0332 - val_accuracy: 0.7647 - val_loss: 0.8447\n",
      "Epoch 53/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0293 - val_accuracy: 0.7647 - val_loss: 0.8467\n",
      "Epoch 54/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0253 - val_accuracy: 0.7941 - val_loss: 0.8732\n",
      "Epoch 55/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0290 - val_accuracy: 0.7941 - val_loss: 0.8944\n",
      "Epoch 56/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0279 - val_accuracy: 0.7353 - val_loss: 0.8868\n",
      "Epoch 57/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0240 - val_accuracy: 0.7647 - val_loss: 0.9052\n",
      "Epoch 58/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0196 - val_accuracy: 0.7647 - val_loss: 0.9213\n",
      "Epoch 59/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0198 - val_accuracy: 0.7647 - val_loss: 0.9420\n",
      "Epoch 60/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0218 - val_accuracy: 0.7647 - val_loss: 0.9357\n",
      "Epoch 61/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0186 - val_accuracy: 0.7647 - val_loss: 0.9478\n",
      "Epoch 62/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0160 - val_accuracy: 0.7353 - val_loss: 0.9363\n",
      "Epoch 63/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 0.7647 - val_loss: 0.9399\n",
      "Epoch 64/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 0.7647 - val_loss: 0.9637\n",
      "Epoch 65/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.7647 - val_loss: 0.9831\n",
      "Epoch 66/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.7647 - val_loss: 0.9914\n",
      "Epoch 67/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 0.7647 - val_loss: 0.9918\n",
      "Epoch 68/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.7647 - val_loss: 1.0099\n",
      "Epoch 69/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.7647 - val_loss: 1.0152\n",
      "Epoch 70/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.7647 - val_loss: 1.0250\n",
      "Epoch 71/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.7647 - val_loss: 1.0246\n",
      "Epoch 72/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.7647 - val_loss: 1.0480\n",
      "Epoch 73/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.7647 - val_loss: 1.0531\n",
      "Epoch 74/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.7647 - val_loss: 1.0537\n",
      "Epoch 75/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.7647 - val_loss: 1.0790\n",
      "Epoch 76/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.7647 - val_loss: 1.0796\n",
      "Epoch 77/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.7647 - val_loss: 1.0827\n",
      "Epoch 78/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.7647 - val_loss: 1.0847\n",
      "Epoch 79/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.7647 - val_loss: 1.0945\n",
      "Epoch 80/80\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.7647 - val_loss: 1.1042\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(60 , input_shape=(60,) , activation = \"relu\"),\n",
    "        keras.layers.Dense(30 , activation = \"relu\"),\n",
    "        keras.layers.Dense(15 , activation = \"relu\"),\n",
    "        keras.layers.Dense(1 , activation = \"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile( \n",
    "    optimizer = \"adam\" ,\n",
    "    loss = \"binary_crossentropy\", \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(x_train , y_train , epochs = 80 , validation_split = 0.2 , batch_size = 8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abedd391",
   "metadata": {},
   "source": [
    "**Model evaluation and Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f3811be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8105 - loss: 0.7905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8154451251029968, 0.8095238208770752]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1a03358e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = np.round(model.predict(x_test)).reshape(-1)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328f795b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Confusion matrix : \n",
      " [[13  2]\n",
      " [ 6 21]]\n"
     ]
    }
   ],
   "source": [
    "print(f\" Confusion matrix  without Dropout Layer: \\n {confusion_matrix(y_test , y_predicted).reshape(2,2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d59d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.87      0.76        15\n",
      "           1       0.91      0.78      0.84        27\n",
      "\n",
      "    accuracy                           0.81        42\n",
      "   macro avg       0.80      0.82      0.80        42\n",
      "weighted avg       0.83      0.81      0.81        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"classification report without Dropout Layer: \\n {classification_report(y_test , y_predicted)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2288d83",
   "metadata": {},
   "source": [
    "**Creating Model With Dropout Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aa730e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\13zer\\anaconda3\\envs\\dl\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.5280 - loss: 0.7287 - val_accuracy: 0.5294 - val_loss: 0.6912\n",
      "Epoch 2/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4267 - loss: 0.7230 - val_accuracy: 0.5294 - val_loss: 0.6921\n",
      "Epoch 3/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5300 - loss: 0.6981 - val_accuracy: 0.6471 - val_loss: 0.6857\n",
      "Epoch 4/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5963 - loss: 0.7152 - val_accuracy: 0.5588 - val_loss: 0.6874\n",
      "Epoch 5/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5748 - loss: 0.6650 - val_accuracy: 0.5294 - val_loss: 0.6862\n",
      "Epoch 6/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4453 - loss: 0.7110 - val_accuracy: 0.6176 - val_loss: 0.6875\n",
      "Epoch 7/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6414 - loss: 0.6530 - val_accuracy: 0.6176 - val_loss: 0.6866\n",
      "Epoch 8/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4559 - loss: 0.7171 - val_accuracy: 0.5000 - val_loss: 0.6922\n",
      "Epoch 9/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6095 - loss: 0.6651 - val_accuracy: 0.4706 - val_loss: 0.6939\n",
      "Epoch 10/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5670 - loss: 0.6805 - val_accuracy: 0.5882 - val_loss: 0.6862\n",
      "Epoch 11/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6115 - loss: 0.6669 - val_accuracy: 0.5000 - val_loss: 0.6859\n",
      "Epoch 12/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6154 - loss: 0.6615 - val_accuracy: 0.5882 - val_loss: 0.6751\n",
      "Epoch 13/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4227 - loss: 0.7103 - val_accuracy: 0.6176 - val_loss: 0.6708\n",
      "Epoch 14/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6215 - loss: 0.6574 - val_accuracy: 0.6176 - val_loss: 0.6669\n",
      "Epoch 15/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5745 - loss: 0.6669 - val_accuracy: 0.5588 - val_loss: 0.6700\n",
      "Epoch 16/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5949 - loss: 0.6681 - val_accuracy: 0.5882 - val_loss: 0.6605\n",
      "Epoch 17/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6358 - loss: 0.6469 - val_accuracy: 0.6176 - val_loss: 0.6468\n",
      "Epoch 18/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6358 - loss: 0.6539 - val_accuracy: 0.5294 - val_loss: 0.6530\n",
      "Epoch 19/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5599 - loss: 0.6572 - val_accuracy: 0.5294 - val_loss: 0.6530\n",
      "Epoch 20/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6801 - loss: 0.6184 - val_accuracy: 0.5882 - val_loss: 0.6353\n",
      "Epoch 21/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6721 - loss: 0.5787 - val_accuracy: 0.6765 - val_loss: 0.6021\n",
      "Epoch 22/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6031 - loss: 0.6178 - val_accuracy: 0.6765 - val_loss: 0.6075\n",
      "Epoch 23/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6456 - loss: 0.6191 - val_accuracy: 0.6765 - val_loss: 0.6051\n",
      "Epoch 24/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8112 - loss: 0.5430 - val_accuracy: 0.7353 - val_loss: 0.5888\n",
      "Epoch 25/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7016 - loss: 0.6036 - val_accuracy: 0.6176 - val_loss: 0.6044\n",
      "Epoch 26/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6585 - loss: 0.5927 - val_accuracy: 0.7353 - val_loss: 0.5641\n",
      "Epoch 27/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7209 - loss: 0.5583 - val_accuracy: 0.6471 - val_loss: 0.5894\n",
      "Epoch 28/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7537 - loss: 0.5917 - val_accuracy: 0.7353 - val_loss: 0.5497\n",
      "Epoch 29/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7355 - loss: 0.5066 - val_accuracy: 0.6176 - val_loss: 0.5793\n",
      "Epoch 30/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7322 - loss: 0.5281 - val_accuracy: 0.7647 - val_loss: 0.5400\n",
      "Epoch 31/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7328 - loss: 0.5148 - val_accuracy: 0.7647 - val_loss: 0.5466\n",
      "Epoch 32/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7050 - loss: 0.5531 - val_accuracy: 0.7647 - val_loss: 0.5295\n",
      "Epoch 33/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8092 - loss: 0.4489 - val_accuracy: 0.6471 - val_loss: 0.5814\n",
      "Epoch 34/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7893 - loss: 0.4744 - val_accuracy: 0.7059 - val_loss: 0.5481\n",
      "Epoch 35/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7542 - loss: 0.4904 - val_accuracy: 0.7353 - val_loss: 0.5505\n",
      "Epoch 36/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7890 - loss: 0.4487 - val_accuracy: 0.6765 - val_loss: 0.5810\n",
      "Epoch 37/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7913 - loss: 0.4777 - val_accuracy: 0.7647 - val_loss: 0.5351\n",
      "Epoch 38/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8095 - loss: 0.3988 - val_accuracy: 0.6765 - val_loss: 0.5517\n",
      "Epoch 39/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7525 - loss: 0.4447 - val_accuracy: 0.7647 - val_loss: 0.5444\n",
      "Epoch 40/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8446 - loss: 0.4088 - val_accuracy: 0.7059 - val_loss: 0.5445\n",
      "Epoch 41/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7679 - loss: 0.4381 - val_accuracy: 0.7647 - val_loss: 0.5274\n",
      "Epoch 42/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8214 - loss: 0.4287 - val_accuracy: 0.7059 - val_loss: 0.5639\n",
      "Epoch 43/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7606 - loss: 0.4923 - val_accuracy: 0.7647 - val_loss: 0.5075\n",
      "Epoch 44/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8501 - loss: 0.4082 - val_accuracy: 0.7941 - val_loss: 0.5145\n",
      "Epoch 45/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7529 - loss: 0.4754 - val_accuracy: 0.7647 - val_loss: 0.5389\n",
      "Epoch 46/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7832 - loss: 0.4143 - val_accuracy: 0.7941 - val_loss: 0.5238\n",
      "Epoch 47/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8212 - loss: 0.4154 - val_accuracy: 0.7059 - val_loss: 0.5846\n",
      "Epoch 48/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8543 - loss: 0.3840 - val_accuracy: 0.7941 - val_loss: 0.5138\n",
      "Epoch 49/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8439 - loss: 0.4144 - val_accuracy: 0.7647 - val_loss: 0.5463\n",
      "Epoch 50/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8555 - loss: 0.3702 - val_accuracy: 0.7941 - val_loss: 0.5735\n",
      "Epoch 51/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8920 - loss: 0.3144 - val_accuracy: 0.7353 - val_loss: 0.5575\n",
      "Epoch 52/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8393 - loss: 0.3080 - val_accuracy: 0.7941 - val_loss: 0.5238\n",
      "Epoch 53/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8896 - loss: 0.2930 - val_accuracy: 0.7059 - val_loss: 0.5911\n",
      "Epoch 54/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8448 - loss: 0.3707 - val_accuracy: 0.7647 - val_loss: 0.5807\n",
      "Epoch 55/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9254 - loss: 0.2838 - val_accuracy: 0.7353 - val_loss: 0.6306\n",
      "Epoch 56/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8786 - loss: 0.3950 - val_accuracy: 0.7647 - val_loss: 0.5793\n",
      "Epoch 57/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8474 - loss: 0.3091 - val_accuracy: 0.7647 - val_loss: 0.5689\n",
      "Epoch 58/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7894 - loss: 0.3851 - val_accuracy: 0.7353 - val_loss: 0.5662\n",
      "Epoch 59/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8594 - loss: 0.2963 - val_accuracy: 0.7647 - val_loss: 0.5472\n",
      "Epoch 60/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8977 - loss: 0.2959 - val_accuracy: 0.7647 - val_loss: 0.5428\n",
      "Epoch 61/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8240 - loss: 0.3714 - val_accuracy: 0.7353 - val_loss: 0.5787\n",
      "Epoch 62/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8966 - loss: 0.2529 - val_accuracy: 0.7941 - val_loss: 0.5521\n",
      "Epoch 63/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8696 - loss: 0.3141 - val_accuracy: 0.7647 - val_loss: 0.5787\n",
      "Epoch 64/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8874 - loss: 0.2453 - val_accuracy: 0.7059 - val_loss: 0.5964\n",
      "Epoch 65/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8649 - loss: 0.3483 - val_accuracy: 0.7941 - val_loss: 0.5622\n",
      "Epoch 66/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8896 - loss: 0.2669 - val_accuracy: 0.7353 - val_loss: 0.5453\n",
      "Epoch 67/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8557 - loss: 0.2848 - val_accuracy: 0.7941 - val_loss: 0.5471\n",
      "Epoch 68/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8930 - loss: 0.2380 - val_accuracy: 0.7647 - val_loss: 0.5866\n",
      "Epoch 69/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9030 - loss: 0.2614 - val_accuracy: 0.7353 - val_loss: 0.5764\n",
      "Epoch 70/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8932 - loss: 0.2739 - val_accuracy: 0.7941 - val_loss: 0.5589\n",
      "Epoch 71/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9130 - loss: 0.3107 - val_accuracy: 0.7647 - val_loss: 0.5888\n",
      "Epoch 72/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9024 - loss: 0.2441 - val_accuracy: 0.7647 - val_loss: 0.6162\n",
      "Epoch 73/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8832 - loss: 0.2341 - val_accuracy: 0.7353 - val_loss: 0.5989\n",
      "Epoch 74/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9067 - loss: 0.2303 - val_accuracy: 0.7941 - val_loss: 0.5716\n",
      "Epoch 75/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9153 - loss: 0.2160 - val_accuracy: 0.7941 - val_loss: 0.5688\n",
      "Epoch 76/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9095 - loss: 0.2212 - val_accuracy: 0.7647 - val_loss: 0.6111\n",
      "Epoch 77/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8510 - loss: 0.2511 - val_accuracy: 0.7647 - val_loss: 0.6276\n",
      "Epoch 78/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8664 - loss: 0.2332 - val_accuracy: 0.7647 - val_loss: 0.6250\n",
      "Epoch 79/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9133 - loss: 0.2420 - val_accuracy: 0.7353 - val_loss: 0.6751\n",
      "Epoch 80/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9083 - loss: 0.1918 - val_accuracy: 0.7647 - val_loss: 0.6463\n",
      "Epoch 81/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9595 - loss: 0.1635 - val_accuracy: 0.7647 - val_loss: 0.7367\n",
      "Epoch 82/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9359 - loss: 0.1954 - val_accuracy: 0.7353 - val_loss: 0.6479\n",
      "Epoch 83/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9382 - loss: 0.1572 - val_accuracy: 0.7941 - val_loss: 0.5713\n",
      "Epoch 84/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8753 - loss: 0.2553 - val_accuracy: 0.7353 - val_loss: 0.6609\n",
      "Epoch 85/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9370 - loss: 0.2094 - val_accuracy: 0.7941 - val_loss: 0.5825\n",
      "Epoch 86/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9091 - loss: 0.2237 - val_accuracy: 0.7353 - val_loss: 0.5946\n",
      "Epoch 87/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9209 - loss: 0.2328 - val_accuracy: 0.7941 - val_loss: 0.5906\n",
      "Epoch 88/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9448 - loss: 0.1684 - val_accuracy: 0.7353 - val_loss: 0.6386\n",
      "Epoch 89/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9606 - loss: 0.1183 - val_accuracy: 0.7647 - val_loss: 0.6595\n",
      "Epoch 90/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9265 - loss: 0.1938 - val_accuracy: 0.7941 - val_loss: 0.6736\n",
      "Epoch 91/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9687 - loss: 0.1529 - val_accuracy: 0.7941 - val_loss: 0.6363\n",
      "Epoch 92/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9397 - loss: 0.2270 - val_accuracy: 0.7647 - val_loss: 0.6481\n",
      "Epoch 93/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9283 - loss: 0.2037 - val_accuracy: 0.7941 - val_loss: 0.6084\n",
      "Epoch 94/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9042 - loss: 0.2390 - val_accuracy: 0.7353 - val_loss: 0.6454\n",
      "Epoch 95/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9331 - loss: 0.1528 - val_accuracy: 0.7647 - val_loss: 0.5916\n",
      "Epoch 96/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9255 - loss: 0.2133 - val_accuracy: 0.7647 - val_loss: 0.5980\n",
      "Epoch 97/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9363 - loss: 0.1591 - val_accuracy: 0.7941 - val_loss: 0.6578\n",
      "Epoch 98/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9082 - loss: 0.2381 - val_accuracy: 0.7647 - val_loss: 0.7073\n",
      "Epoch 99/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9339 - loss: 0.1659 - val_accuracy: 0.7941 - val_loss: 0.7332\n",
      "Epoch 100/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9640 - loss: 0.1496 - val_accuracy: 0.7647 - val_loss: 0.6892\n"
     ]
    }
   ],
   "source": [
    "model1= keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(100 , input_shape=(60,) , activation = \"relu\"),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(40 , activation = \"relu\"),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(25 , activation = \"relu\"),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1 , activation = \"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model1.compile( \n",
    "    optimizer = \"adam\" ,\n",
    "    loss = \"binary_crossentropy\", \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = model1.fit(x_train , y_train , epochs = 100 , validation_split = 0.2 , batch_size = 8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471faaee",
   "metadata": {},
   "source": [
    "**Model evaluation and Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "da8b5ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8631 - loss: 0.3128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3324354887008667, 0.8571428656578064]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ccee4d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001D49EDA7420> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/stepWARNING:tensorflow:6 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001D49EDA7420> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n"
     ]
    }
   ],
   "source": [
    "y_predicted_1 = np.round(model1.predict(x_test)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7893af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Confusion matrix : \n",
      " [[14  1]\n",
      " [ 5 22]]\n"
     ]
    }
   ],
   "source": [
    "print(f\" Confusion matrix with Dropout Layer: \\n {confusion_matrix(y_test , y_predicted_1).reshape(2,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875d7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.93      0.82        15\n",
      "           1       0.96      0.81      0.88        27\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.85      0.87      0.85        42\n",
      "weighted avg       0.88      0.86      0.86        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"classification report with Dropout Layer: \\n {classification_report(y_test , y_predicted_1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c823da3",
   "metadata": {},
   "source": [
    "*as we can see there is a significant increase in all metrics of Classification report for Model1*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
